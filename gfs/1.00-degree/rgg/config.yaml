defaults:
- data: zarr
- dataloader: native_grid
- datamodule: single
- diagnostics: evaluation
- hardware: slurm
- graph: encoder_decoder_only
- model: transformer
- training: default
- _self_

config_validation: True

data:
  forcing:
    - cos_latitude
    - sin_latitude
    - cos_longitude
    - sin_longitude
    - cos_julian_day
    - sin_julian_day
    - cos_local_time
    - sin_local_time
    - insolation
    - lsm
    - orog
  diagnostic:
    - accum_tp
    - u80
    - v80
  normalizer:
    default: mean-std
    std:
      - accum_tp
      - sh2
      - q_100
      - q_150
      - q_200
      - q_250
      - q_300
      - q_400
      - q_500
      - q_600
      - q_700
      - q_850
      - q_925
      - q_1000
    max:
      - orog
    none:
      - cos_latitude
      - sin_latitude
      - cos_longitude
      - sin_longitude
      - cos_julian_day
      - sin_julian_day
      - cos_local_time
      - sin_local_time
      - insolation
      - lsm

dataloader:
  read_group_size: 1
  batch_size:
    training: 1
    validation: 1
    test: 1
  num_workers:
    training: 4
    validation: 4
    test: 4
  dataset:
    # Global forcing
    join:
      - dataset: ${hardware.paths.data}/${hardware.files.global_analysis}
        set_missing_dates:
          - 2015-08-02T12:00:00
          - 2016-10-22T12:00:00
      - dataset: ${hardware.paths.data}/${hardware.files.global_forecast}
        set_missing_dates:
          - 2015-08-02T12:00:00
          - 2016-10-22T12:00:00
  training:
    start: 2015-02-01
    end: 2023-01-31
  validation:
    start: 2023-02-01
    end: 2024-01-31
  test:
    start: 2023-02-01
    end: 2024-01-31

diagnostics:
  log:
    wandb:
      enabled: False
      entity: null
    mlflow:
      enabled: True
      offline: False
      authentication: False
      log_model: False
      tracking_uri: null
      experiment_name: 'gfs-one-degree'
      project_name: 'anemoi-house'
      use_azure: True
      aml_resource_group: "PSL-PMP-ML"
      aml_workspace_name: "psl-ml-workspace"
      system: True
      terminal: True
      run_name: null # If set to null, the run name will be the a random UUID
      on_resume_create_child: True
      expand_hyperparams: # Which keys in hyperparams to expand
        - config
      http_max_retries: 35
  plot:
    frequency:
      batch: 30_000
      epoch: 5
    parameters:
      - gh_500
      - t_850
      - u_850
      - v_850
      - t2m
      - sh2
      - u10
      - v10
      - sp
      - accum_tp
    precip_and_related_fields: [accum_tp]
    callbacks:
      - _target_: anemoi.training.diagnostics.callbacks.plot.GraphTrainableFeaturesPlot
        every_n_epochs: ${diagnostics.plot.frequency.epoch}
      - _target_: anemoi.training.diagnostics.callbacks.plot.PlotLoss
        parameter_groups:
          moisture: [accum_tp]
          sfc_wind: [u10, v10]
        every_n_batches: ${diagnostics.plot.frequency.batch}
      - _target_: anemoi.training.diagnostics.callbacks.plot.PlotSample
        sample_idx: ${diagnostics.plot.sample_idx}
        per_sample : 6
        parameters: ${diagnostics.plot.parameters}
        every_n_batches: ${diagnostics.plot.frequency.batch}
        #Defining the accumulation levels for precipitation related fields and the colormap
        accumulation_levels_plot: [0, 0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 3, 4, 5, 6, 7, 100] # in mm
        precip_and_related_fields: ${diagnostics.plot.precip_and_related_fields}
        colormaps: ${diagnostics.plot.colormaps}
      - _target_: anemoi.training.diagnostics.callbacks.plot.PlotSpectrum
        sample_idx: ${diagnostics.plot.sample_idx}
        every_n_batches: ${diagnostics.plot.frequency.batch}
        parameters:
        - gh_500
        - accum_tp
        - t2m
        - u10
        - v10
      - _target_: anemoi.training.diagnostics.callbacks.plot.PlotHistogram
        sample_idx: ${diagnostics.plot.sample_idx}
        every_n_batches: ${diagnostics.plot.frequency.batch}
        precip_and_related_fields: ${diagnostics.plot.precip_and_related_fields}
        parameters:
        - gh_500
        - accum_tp
        - t2m
        - u10
        - v10

graph:
  overwrite: False
  nodes:
    data:
      node_builder:
        _target_: anemoi.graphs.nodes.AnemoiDatasetNodes
        dataset: ${dataloader.dataset}
      attributes: ${graph.attributes.nodes}
    hidden:
      node_builder:
        _target_: anemoi.graphs.nodes.ReducedGaussianGridNodes
        grid: o48
  edges:
  # Encoder configuration
  - source_name: ${graph.data}
    target_name: ${graph.hidden}
    edge_builders:
    - _target_: anemoi.graphs.edges.CutOffEdges
      cutoff_factor: 0.7
      source_mask_attr_name: null
      target_mask_attr_name: null
    attributes: ${graph.attributes.edges}
  # Decoder configuration
  - source_name: ${graph.hidden}
    target_name: ${graph.data}
    edge_builders:
    - _target_: anemoi.graphs.edges.KNNEdges
      num_nearest_neighbours: 3
      source_mask_attr_name: null
      target_mask_attr_name: null
    attributes: ${graph.attributes.edges}
  attributes:
    nodes:
      area_weight:
        _target_: anemoi.graphs.nodes.attributes.SphericalAreaWeights
        norm: unit-max
        fill_value: 0
    edges:
      edge_length:
        _target_: anemoi.graphs.edges.attributes.EdgeLength
        norm: unit-std
      edge_dirs:
        _target_: anemoi.graphs.edges.attributes.EdgeDirection
        norm: unit-std

hardware:
  num_gpus_per_model: 1
  paths:
    data: ${oc.decode:${oc.env:SCRATCH}}/anemoi-house/gfs/1.00-degree/data
    graph: ${oc.decode:${oc.env:SCRATCH}}/anemoi-house/gfs/1.00-degree/rgg/
    output: ${oc.decode:${oc.env:SCRATCH}}/anemoi-house/gfs/1.00-degree/rgg/
  files:
    graph: graph.o48.pt
    global_analysis: gfs.analysis.zarr
    global_forecast: gfs.forecast.zarr

model:
  num_channels: 512 #???
  processor:
    window_size: 512 #??? unclear if all processor options need to be added here or not
  bounding:
    - _target_: anemoi.models.layers.bounding.ReluBounding #[0, infinity)
      variables:
      - accum_tp
      - sh2
      - q_100
      - q_150
      - q_200
      - q_250
      - q_300
      - q_400
      - q_500
      - q_600
      - q_700
      - q_850
      - q_925
      - q_1000

training:
  max_steps: 300_000
  # LR = local_rate * num_gpus_per_node * num_nodes / gpus_per_model
  #    = local_rate * total_gpus / gpus_per_model
  lr:
    warmup: 1000
    rate: 0.625e-4
    iterations: ${training.max_steps}
    min: 3e-7
  variable_groups:
    default: sfc
    pl:
      param: [gh, u, v, w, t, q]
  metrics:
    - gh_500
    - t_850
    - u_850
    - v_850
  scalers:
    general_variable:
      _target_: anemoi.training.losses.scalers.GeneralVariableLossScaler
      weights:
        default: 1
        q: 0.6 #1
        t: 6   #1
        u: 0.8 #0.5
        v: 0.5 #0.33
        w: 0.001
        gh: 12  #1
        sp: 10
        u10: 0.1
        v10: 0.1
        accum_tp: 0.025

    ## tendency scalers
    ## scale the prognostic losses by the stdev of the variable tendencies (e.g. the 6-hourly differences of the data)
    ## useful if including slow vs fast evolving variables in the training (e.g. Land/Ocean vs Atmosphere)
    ## if using this option 'variable_loss_scalings' should all be set close to 1.0 for prognostic variables
    #stdev_tendency:
    #  _target_: anemoi.training.losses.scalers.StdevTendencyScaler

    #var_tendency:
    #  _target_: anemoi.training.losses.scalers.VarTendencyScaler

    # Scalers from node attributes
    node_weights:
      _target_: anemoi.training.losses.scalers.GraphNodeAttributeScaler
      nodes_name: ${graph.data}
      nodes_attribute_name: area_weight
      norm: unit-sum
